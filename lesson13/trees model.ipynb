{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "train = pd.read_csv('spam_train.csv')\n",
    "test = pd.read_csv('spam_test.csv')\n",
    "## separate the predictors and response in the training data set\n",
    "x_train = train.iloc[:, 0:57]\n",
    "y_train = np.array(train.iloc[:, -1])\n",
    "## separate the predictors and response in the test data set\n",
    "x_test = test.iloc[:, 0:57]\n",
    "y_test = np.array(test.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A.1</th>\n",
       "      <th>A.2</th>\n",
       "      <th>A.3</th>\n",
       "      <th>A.4</th>\n",
       "      <th>A.5</th>\n",
       "      <th>A.6</th>\n",
       "      <th>A.7</th>\n",
       "      <th>A.8</th>\n",
       "      <th>A.9</th>\n",
       "      <th>A.10</th>\n",
       "      <th>...</th>\n",
       "      <th>A.49</th>\n",
       "      <th>A.50</th>\n",
       "      <th>A.51</th>\n",
       "      <th>A.52</th>\n",
       "      <th>A.53</th>\n",
       "      <th>A.54</th>\n",
       "      <th>A.55</th>\n",
       "      <th>A.56</th>\n",
       "      <th>A.57</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.068</td>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.685</td>\n",
       "      <td>7</td>\n",
       "      <td>204</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.800</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.424</td>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    A.1  A.2   A.3  A.4   A.5   A.6  A.7  A.8  A.9  A.10  ...  A.49   A.50  \\\n",
       "0  0.32  0.0  0.00  0.0  0.32  0.00  0.0  0.0  0.0   0.0  ...   0.0  0.234   \n",
       "1  0.00  0.0  0.71  0.0  0.00  0.00  0.0  0.0  0.0   0.0  ...   0.0  0.000   \n",
       "2  0.00  0.0  0.00  0.0  0.00  0.17  0.0  0.0  0.0   0.0  ...   0.0  0.055   \n",
       "3  0.00  0.0  0.00  0.0  0.00  0.00  0.0  0.0  0.0   0.0  ...   0.0  0.000   \n",
       "4  0.00  0.0  0.00  0.0  0.00  0.00  0.0  0.0  0.0   0.0  ...   0.0  0.471   \n",
       "\n",
       "   A.51   A.52  A.53  A.54   A.55  A.56  A.57   spam  \n",
       "0   0.0  0.058   0.0   0.0  1.068     3    47  email  \n",
       "1   0.0  0.342   0.0   0.0  1.000     1    31  email  \n",
       "2   0.0  0.000   0.0   0.0  1.685     7   204  email  \n",
       "3   0.0  0.000   0.0   0.0  1.800     5     9  email  \n",
       "4   0.0  0.000   0.0   0.0  1.424     8    47  email  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2300, 58)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2301, 58)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classfication tree: default gini\n",
    "from sklearn import tree\n",
    "tree_model = tree.DecisionTreeClassifier() #DecisionTreeRegressor\n",
    "from sklearn import cross_validation, metrics\n",
    "tree_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_model\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train=tree_model.predict(x_train) #predict_prob\n",
    "pred_test=tree_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'email', 'spam'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy : 0.9996\n",
      "testing accuracy : 0.9022\n"
     ]
    }
   ],
   "source": [
    "print \"training accuracy : %.4g\" % metrics.accuracy_score(y_train, pred_train)\n",
    "print \"testing accuracy : %.4g\" % metrics.accuracy_score(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>A.53</td>\n",
       "      <td>0.323941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A.7</td>\n",
       "      <td>0.171245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>A.52</td>\n",
       "      <td>0.092352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>A.25</td>\n",
       "      <td>0.066213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>A.57</td>\n",
       "      <td>0.045231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A.16</td>\n",
       "      <td>0.027739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>A.55</td>\n",
       "      <td>0.027463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>A.56</td>\n",
       "      <td>0.024638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>A.21</td>\n",
       "      <td>0.020080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>A.46</td>\n",
       "      <td>0.019670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A.19</td>\n",
       "      <td>0.018256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>A.50</td>\n",
       "      <td>0.016650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A.5</td>\n",
       "      <td>0.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>A.45</td>\n",
       "      <td>0.014832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>A.39</td>\n",
       "      <td>0.012071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A.10</td>\n",
       "      <td>0.011855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>A.24</td>\n",
       "      <td>0.009444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A.18</td>\n",
       "      <td>0.008594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A.8</td>\n",
       "      <td>0.007767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A.11</td>\n",
       "      <td>0.005805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A.17</td>\n",
       "      <td>0.005436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>A.42</td>\n",
       "      <td>0.005170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A.2</td>\n",
       "      <td>0.004697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>A.51</td>\n",
       "      <td>0.004667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A.1</td>\n",
       "      <td>0.004297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A.27</td>\n",
       "      <td>0.003754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>A.43</td>\n",
       "      <td>0.003561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>A.23</td>\n",
       "      <td>0.003413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>A.28</td>\n",
       "      <td>0.003325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A.12</td>\n",
       "      <td>0.003075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A.6</td>\n",
       "      <td>0.003024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A.9</td>\n",
       "      <td>0.002981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>A.35</td>\n",
       "      <td>0.002772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>A.29</td>\n",
       "      <td>0.002661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>A.37</td>\n",
       "      <td>0.002405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>A.36</td>\n",
       "      <td>0.001662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>A.22</td>\n",
       "      <td>0.001438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>A.33</td>\n",
       "      <td>0.001364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A.14</td>\n",
       "      <td>0.000529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A.20</td>\n",
       "      <td>0.000526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>A.41</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A.13</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A.3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A.4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>A.54</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>A.30</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>A.31</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>A.32</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>A.49</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>A.40</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>A.48</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>A.47</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>A.34</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A.15</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>A.44</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>A.38</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>A.26</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature  importance\n",
       "52    A.53    0.323941\n",
       "6      A.7    0.171245\n",
       "51    A.52    0.092352\n",
       "24    A.25    0.066213\n",
       "56    A.57    0.045231\n",
       "15    A.16    0.027739\n",
       "54    A.55    0.027463\n",
       "55    A.56    0.024638\n",
       "20    A.21    0.020080\n",
       "45    A.46    0.019670\n",
       "18    A.19    0.018256\n",
       "49    A.50    0.016650\n",
       "4      A.5    0.015400\n",
       "44    A.45    0.014832\n",
       "38    A.39    0.012071\n",
       "9     A.10    0.011855\n",
       "23    A.24    0.009444\n",
       "17    A.18    0.008594\n",
       "7      A.8    0.007767\n",
       "10    A.11    0.005805\n",
       "16    A.17    0.005436\n",
       "41    A.42    0.005170\n",
       "1      A.2    0.004697\n",
       "50    A.51    0.004667\n",
       "0      A.1    0.004297\n",
       "26    A.27    0.003754\n",
       "42    A.43    0.003561\n",
       "22    A.23    0.003413\n",
       "27    A.28    0.003325\n",
       "11    A.12    0.003075\n",
       "5      A.6    0.003024\n",
       "8      A.9    0.002981\n",
       "34    A.35    0.002772\n",
       "28    A.29    0.002661\n",
       "36    A.37    0.002405\n",
       "35    A.36    0.001662\n",
       "21    A.22    0.001438\n",
       "32    A.33    0.001364\n",
       "13    A.14    0.000529\n",
       "19    A.20    0.000526\n",
       "40    A.41    0.000000\n",
       "12    A.13    0.000000\n",
       "2      A.3    0.000000\n",
       "3      A.4    0.000000\n",
       "53    A.54    0.000000\n",
       "29    A.30    0.000000\n",
       "30    A.31    0.000000\n",
       "31    A.32    0.000000\n",
       "48    A.49    0.000000\n",
       "39    A.40    0.000000\n",
       "47    A.48    0.000000\n",
       "46    A.47    0.000000\n",
       "33    A.34    0.000000\n",
       "14    A.15    0.000000\n",
       "43    A.44    0.000000\n",
       "37    A.38    0.000000\n",
       "25    A.26    0.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imprtance=pd.DataFrame(train.columns[:-1],columns=['Feature'])\n",
    "feature_imprtance['importance']=tree_model.feature_importances_\n",
    "feature_imprtance.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change gini to entropy\n",
    "tree_model = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "tree_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train=tree_model.predict(x_train)\n",
    "pred_test=tree_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy : 0.9996\n",
      "testing accuracy : 0.9009\n"
     ]
    }
   ],
   "source": [
    "print \"training accuracy : %.4g\" % metrics.accuracy_score(y_train, pred_train)\n",
    "print \"testing accuracy : %.4g\" % metrics.accuracy_score(y_test, pred_test) # gini is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>A.52</td>\n",
       "      <td>0.281206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>A.55</td>\n",
       "      <td>0.128241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A.7</td>\n",
       "      <td>0.112446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>A.53</td>\n",
       "      <td>0.057646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>A.25</td>\n",
       "      <td>0.057077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A.16</td>\n",
       "      <td>0.049065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>A.21</td>\n",
       "      <td>0.033808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>A.57</td>\n",
       "      <td>0.028640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A.27</td>\n",
       "      <td>0.023895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>A.56</td>\n",
       "      <td>0.023774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>A.45</td>\n",
       "      <td>0.022985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>A.46</td>\n",
       "      <td>0.021049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A.19</td>\n",
       "      <td>0.015231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A.8</td>\n",
       "      <td>0.014571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A.12</td>\n",
       "      <td>0.014142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A.10</td>\n",
       "      <td>0.014111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A.5</td>\n",
       "      <td>0.012779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A.17</td>\n",
       "      <td>0.011994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>A.26</td>\n",
       "      <td>0.011918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>A.50</td>\n",
       "      <td>0.010181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A.6</td>\n",
       "      <td>0.007079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>A.37</td>\n",
       "      <td>0.007022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A.1</td>\n",
       "      <td>0.005195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A.18</td>\n",
       "      <td>0.004879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>A.23</td>\n",
       "      <td>0.004702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A.3</td>\n",
       "      <td>0.003798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>A.24</td>\n",
       "      <td>0.003709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>A.43</td>\n",
       "      <td>0.003307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>A.42</td>\n",
       "      <td>0.002788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>A.38</td>\n",
       "      <td>0.002116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A.14</td>\n",
       "      <td>0.002006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A.13</td>\n",
       "      <td>0.001980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A.2</td>\n",
       "      <td>0.001861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>A.44</td>\n",
       "      <td>0.001778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>A.22</td>\n",
       "      <td>0.001573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>A.49</td>\n",
       "      <td>0.001446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>A.51</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A.15</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>A.48</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A.11</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A.9</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>A.47</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>A.54</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A.4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>A.41</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>A.40</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>A.39</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>A.36</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>A.35</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>A.34</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>A.33</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>A.32</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>A.31</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>A.30</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>A.28</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A.20</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>A.29</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature  importance\n",
       "51    A.52    0.281206\n",
       "54    A.55    0.128241\n",
       "6      A.7    0.112446\n",
       "52    A.53    0.057646\n",
       "24    A.25    0.057077\n",
       "15    A.16    0.049065\n",
       "20    A.21    0.033808\n",
       "56    A.57    0.028640\n",
       "26    A.27    0.023895\n",
       "55    A.56    0.023774\n",
       "44    A.45    0.022985\n",
       "45    A.46    0.021049\n",
       "18    A.19    0.015231\n",
       "7      A.8    0.014571\n",
       "11    A.12    0.014142\n",
       "9     A.10    0.014111\n",
       "4      A.5    0.012779\n",
       "16    A.17    0.011994\n",
       "25    A.26    0.011918\n",
       "49    A.50    0.010181\n",
       "5      A.6    0.007079\n",
       "36    A.37    0.007022\n",
       "0      A.1    0.005195\n",
       "17    A.18    0.004879\n",
       "22    A.23    0.004702\n",
       "2      A.3    0.003798\n",
       "23    A.24    0.003709\n",
       "42    A.43    0.003307\n",
       "41    A.42    0.002788\n",
       "37    A.38    0.002116\n",
       "13    A.14    0.002006\n",
       "12    A.13    0.001980\n",
       "1      A.2    0.001861\n",
       "43    A.44    0.001778\n",
       "21    A.22    0.001573\n",
       "48    A.49    0.001446\n",
       "50    A.51    0.000000\n",
       "14    A.15    0.000000\n",
       "47    A.48    0.000000\n",
       "10    A.11    0.000000\n",
       "8      A.9    0.000000\n",
       "46    A.47    0.000000\n",
       "53    A.54    0.000000\n",
       "3      A.4    0.000000\n",
       "40    A.41    0.000000\n",
       "39    A.40    0.000000\n",
       "38    A.39    0.000000\n",
       "35    A.36    0.000000\n",
       "34    A.35    0.000000\n",
       "33    A.34    0.000000\n",
       "32    A.33    0.000000\n",
       "31    A.32    0.000000\n",
       "30    A.31    0.000000\n",
       "29    A.30    0.000000\n",
       "27    A.28    0.000000\n",
       "19    A.20    0.000000\n",
       "28    A.29    0.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imprtance=pd.DataFrame(train.columns[:-1],columns=['Feature'])\n",
    "feature_imprtance['importance']=tree_model.feature_importances_\n",
    "feature_imprtance.sort_values(by='importance', ascending=False) # feature importance is changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'criterion': ['gini', 'entropy'], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prune the trees\n",
    "# min_samples_split: The minimum number of samples required to split an internal node:\n",
    "import sklearn.grid_search as gs\n",
    "np.random.seed(1)\n",
    "tree_model = tree.DecisionTreeClassifier()\n",
    "grid_para_tree = [{\"criterion\": [\"gini\", \"entropy\"], \"min_samples_leaf\": range(1, 20)}]\n",
    "grid_search_tree = gs.GridSearchCV(tree_model, grid_para_tree, cv=5, scoring='accuracy')\n",
    "grid_search_tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'min_samples_leaf': 5}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## best parameter\n",
    "grid_search_tree.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## best score\n",
    "grid_search_tree.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train=grid_search_tree.predict(x_train)\n",
    "pred_test=grid_search_tree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy : 0.9687\n",
      "testing accuracy : 0.9083\n"
     ]
    }
   ],
   "source": [
    "print \"training accuracy : %.4g\" % metrics.accuracy_score(y_train, pred_train)\n",
    "print \"testing accuracy : %.4g\" % metrics.accuracy_score(y_test, pred_test) # better than classfication tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest: default max_feature sqrt(p)\n",
    "from sklearn import ensemble\n",
    "randomForest = ensemble.RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "randomForest.set_params(n_estimators=50)\n",
    "randomForest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train=randomForest.predict(x_train)\n",
    "pred_test=randomForest.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy : 0.9996\n",
      "testing accuracy : 0.9422\n"
     ]
    }
   ],
   "source": [
    "print \"training accuracy : %.4g\" % metrics.accuracy_score(y_train, pred_train)\n",
    "print \"testing accuracy : %.4g\" % metrics.accuracy_score(y_test, pred_test)# better than pruning tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>A.52</td>\n",
       "      <td>0.137031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>A.53</td>\n",
       "      <td>0.101383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>A.55</td>\n",
       "      <td>0.080020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A.7</td>\n",
       "      <td>0.077506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>A.57</td>\n",
       "      <td>0.053551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>A.21</td>\n",
       "      <td>0.053418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A.16</td>\n",
       "      <td>0.048718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>A.56</td>\n",
       "      <td>0.046099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>A.25</td>\n",
       "      <td>0.040302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>A.24</td>\n",
       "      <td>0.036864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A.5</td>\n",
       "      <td>0.036597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A.19</td>\n",
       "      <td>0.027636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>A.23</td>\n",
       "      <td>0.017169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A.27</td>\n",
       "      <td>0.016504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A.17</td>\n",
       "      <td>0.014865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>A.46</td>\n",
       "      <td>0.014123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A.11</td>\n",
       "      <td>0.013885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>A.26</td>\n",
       "      <td>0.013416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>A.50</td>\n",
       "      <td>0.012216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A.8</td>\n",
       "      <td>0.011702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>A.37</td>\n",
       "      <td>0.011198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A.12</td>\n",
       "      <td>0.010480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A.18</td>\n",
       "      <td>0.009621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>A.45</td>\n",
       "      <td>0.009262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A.3</td>\n",
       "      <td>0.008675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A.10</td>\n",
       "      <td>0.008144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A.6</td>\n",
       "      <td>0.007181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>A.28</td>\n",
       "      <td>0.005835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>A.49</td>\n",
       "      <td>0.005789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>A.35</td>\n",
       "      <td>0.005716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>A.36</td>\n",
       "      <td>0.005322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A.13</td>\n",
       "      <td>0.005037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>A.42</td>\n",
       "      <td>0.004891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>A.39</td>\n",
       "      <td>0.004617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A.2</td>\n",
       "      <td>0.004545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A.1</td>\n",
       "      <td>0.004184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A.9</td>\n",
       "      <td>0.003930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>A.51</td>\n",
       "      <td>0.003685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>A.33</td>\n",
       "      <td>0.003104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A.20</td>\n",
       "      <td>0.002680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>A.54</td>\n",
       "      <td>0.002604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>A.43</td>\n",
       "      <td>0.002600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>A.22</td>\n",
       "      <td>0.002379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>A.30</td>\n",
       "      <td>0.002373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>A.44</td>\n",
       "      <td>0.001846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>A.31</td>\n",
       "      <td>0.001622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>A.40</td>\n",
       "      <td>0.001451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>A.29</td>\n",
       "      <td>0.001439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A.15</td>\n",
       "      <td>0.001273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>A.38</td>\n",
       "      <td>0.001125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>A.41</td>\n",
       "      <td>0.001097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A.14</td>\n",
       "      <td>0.001074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>A.34</td>\n",
       "      <td>0.000809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>A.48</td>\n",
       "      <td>0.000499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>A.32</td>\n",
       "      <td>0.000473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A.4</td>\n",
       "      <td>0.000332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>A.47</td>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature  importance\n",
       "51    A.52    0.137031\n",
       "52    A.53    0.101383\n",
       "54    A.55    0.080020\n",
       "6      A.7    0.077506\n",
       "56    A.57    0.053551\n",
       "20    A.21    0.053418\n",
       "15    A.16    0.048718\n",
       "55    A.56    0.046099\n",
       "24    A.25    0.040302\n",
       "23    A.24    0.036864\n",
       "4      A.5    0.036597\n",
       "18    A.19    0.027636\n",
       "22    A.23    0.017169\n",
       "26    A.27    0.016504\n",
       "16    A.17    0.014865\n",
       "45    A.46    0.014123\n",
       "10    A.11    0.013885\n",
       "25    A.26    0.013416\n",
       "49    A.50    0.012216\n",
       "7      A.8    0.011702\n",
       "36    A.37    0.011198\n",
       "11    A.12    0.010480\n",
       "17    A.18    0.009621\n",
       "44    A.45    0.009262\n",
       "2      A.3    0.008675\n",
       "9     A.10    0.008144\n",
       "5      A.6    0.007181\n",
       "27    A.28    0.005835\n",
       "48    A.49    0.005789\n",
       "34    A.35    0.005716\n",
       "35    A.36    0.005322\n",
       "12    A.13    0.005037\n",
       "41    A.42    0.004891\n",
       "38    A.39    0.004617\n",
       "1      A.2    0.004545\n",
       "0      A.1    0.004184\n",
       "8      A.9    0.003930\n",
       "50    A.51    0.003685\n",
       "32    A.33    0.003104\n",
       "19    A.20    0.002680\n",
       "53    A.54    0.002604\n",
       "42    A.43    0.002600\n",
       "21    A.22    0.002379\n",
       "29    A.30    0.002373\n",
       "43    A.44    0.001846\n",
       "30    A.31    0.001622\n",
       "39    A.40    0.001451\n",
       "28    A.29    0.001439\n",
       "14    A.15    0.001273\n",
       "37    A.38    0.001125\n",
       "40    A.41    0.001097\n",
       "13    A.14    0.001074\n",
       "33    A.34    0.000809\n",
       "47    A.48    0.000499\n",
       "31    A.32    0.000473\n",
       "3      A.4    0.000332\n",
       "46    A.47    0.000104"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imprtance=pd.DataFrame(train.columns[:-1],columns=['Feature'])\n",
    "feature_imprtance['importance']=randomForest.feature_importances_\n",
    "feature_imprtance.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=57, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bagging\n",
    "np.random.seed(1)\n",
    "randomForest.set_params(n_estimators=50, max_features=57)\n",
    "randomForest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train=randomForest.predict(x_train)\n",
    "pred_test=randomForest.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy : 0.9996\n",
      "testing accuracy : 0.9266\n"
     ]
    }
   ],
   "source": [
    "print \"training accuracy : %.4g\" % metrics.accuracy_score(y_train, pred_train)\n",
    "print \"testing accuracy : %.4g\" % metrics.accuracy_score(y_test, pred_test)# worse than random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "randomForest = ensemble.RandomForestClassifier() \n",
    "import sklearn.grid_search as gs\n",
    "# max_feature: feature considered for splitting\n",
    "# n_estimators: number of tree\n",
    "# min_samples_split: The minimum number of samples required to split an internal node:\n",
    "# min_samples_leaf: The minimum number of samples required to be at a leaf node\n",
    "\n",
    "grid_para_forest = [{\"n_estimators\": [10, 50, 100], \"criterion\": [\"gini\", \"entropy\"], \\\n",
    "                    \"min_samples_leaf\": range(1, 10), \"min_samples_split\": range(2, 30, 2),\\\n",
    "                    'max_features':range(3,10,1)}] \n",
    "grid_search_forest = gs.GridSearchCV(randomForest, grid_para_forest, scoring='accuracy', cv=5)\n",
    "grid_search_forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_features': 3,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_forest.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train=grid_search_forest.predict(x_train)\n",
    "pred_test=grid_search_forest.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy : 0.9996\n",
      "testing accuracy : 0.9452\n"
     ]
    }
   ],
   "source": [
    "print \"training accuracy : %.4g\" % metrics.accuracy_score(y_train, pred_train)\n",
    "print \"testing accuracy : %.4g\" % metrics.accuracy_score(y_test, pred_test) # best random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gbm\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "np.random.seed(1)\n",
    "GBM=GradientBoostingClassifier(n_estimators=50)\n",
    "GBM.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train=GBM.predict(x_train)\n",
    "pred_test=GBM.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy : 0.9539\n",
      "testing accuracy : 0.9344\n"
     ]
    }
   ],
   "source": [
    "print \"training accuracy : %.4g\" % metrics.accuracy_score(y_train, pred_train)\n",
    "print \"testing accuracy : %.4g\" % metrics.accuracy_score(y_test, pred_test) # worse than random forest, overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['email', 'email', 'email', ..., 'email', 'email', 'spam'], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict class\n",
    "GBM.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0333752 ,  0.17857711,  0.04552774, ...,  0.0943025 ,\n",
       "        0.08174416,  0.97825915])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict the probability of spam\n",
    "GBM.predict_proba(x_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=10, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [20, 30, 40, 50, 60, 70, 80]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# higher fixed learning rate and number of estimators for tuning tree-based parameters\n",
    "param_test1 = {'n_estimators':range(20,81,10)}\n",
    "gsearch1 = gs.GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1,random_state=10),\n",
    "                        param_grid = param_test1, scoring='accuracy', cv=5)\n",
    "gsearch1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 50}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best n_estimators: 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 13, 'min_samples_split': 400}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the variables with a higher impact on outcome first,  max_depth and min_samples_split have a significant impact \n",
    "# and we will tune those first.\n",
    "param_test2 = {'max_depth':range(5,16,2), 'min_samples_split':range(200,1001, 200)}\n",
    "gsearch2 =gs.GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=50, random_state=10), \n",
    "                        param_grid = param_test2, scoring='accuracy',cv=5)\n",
    "gsearch2.fit(x_train,y_train)\n",
    "gsearch2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'n_estimators': 50, 'max_depth': 13, 'min_samples_split': 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 24}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test3 = {'min_samples_leaf':range(10,30,2)}\n",
    "gsearch3 = gs.GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=50,\n",
    "                                                                  max_depth=13, min_samples_split=400,\n",
    "                                                                  random_state=10), \n",
    "                        param_grid = param_test3, scoring='accuracy', cv=5)\n",
    "gsearch3.fit(x_train, y_train)\n",
    "gsearch3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'n_estimators': 50, 'max_depth': 13, 'min_samples_split': 400, 'min_samples_leaf': 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 16}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test4 = {'max_features':range(2,20,1)}\n",
    "gsearch4 =gs.GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=50,\n",
    "                                                               max_depth=13, min_samples_split=400,\n",
    "                                                               min_samples_leaf=24,  random_state=10),\n",
    "                        param_grid = param_test4, scoring='accuracy',cv=5)\n",
    "gsearch4.fit(x_train, y_train)\n",
    "gsearch4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'n_estimators': 50, 'max_depth': 13, 'min_samples_split': 400, 'min_samples_leaf': 24, 'max_features': 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.85}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test5 = {'subsample':[0.6,0.7,0.75,0.8,0.85,0.9]}\n",
    "gsearch5 = gs.GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=50,\n",
    "                                                               max_depth=13,min_samples_split=400, \n",
    "                                                               min_samples_leaf=24,random_state=10,\n",
    "                                                               max_features=16),\n",
    "                        param_grid = param_test5, scoring='accuracy', cv=5)\n",
    "gsearch5.fit(x_train, y_train)\n",
    "gsearch5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'n_estimators': 50, 'max_depth': 13, 'min_samples_split': 400, 'min_samples_leaf': 24, 'max_features': 16\n",
    "# 'subsample': 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.05, 'n_estimators': 400}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# increase trees and decrease learning rate\n",
    "param_test6 = {'n_estimators':range(100,1000,100), 'learning_rate': [0.1, 0.05, 0.01]}\n",
    "gsearch6 = gs.GridSearchCV(estimator = GradientBoostingClassifier(max_depth=13,min_samples_split=400, \n",
    "                                                               min_samples_leaf=24, subsample=0.85, \n",
    "                                                               random_state=10,max_features=16),\n",
    "                        param_grid = param_test6, scoring='accuracy', cv=5)\n",
    "gsearch6.fit(x_train, y_train)\n",
    "gsearch6.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth=13,min_samples_split=400, min_samples_leaf=24, subsample=0.85, \n",
    "# max_features=16, learning_rate=0.05, n_estimators=400\n",
    "pred_train=gsearch6.predict(x_train)\n",
    "pred_test=gsearch6.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy : 0.9978\n",
      "testing accuracy : 0.9492\n"
     ]
    }
   ],
   "source": [
    "print \"training accuracy : %.4g\" % metrics.accuracy_score(y_train, pred_train)\n",
    "print \"testing accuracy : %.4g\" % metrics.accuracy_score(y_test, pred_test) # better than best random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(n_estimators=50)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "XGB=XGBClassifier(n_estimators=50)\n",
    "XGB.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train=XGB.predict(x_train)\n",
    "pred_test=XGB.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy : 0.9509\n",
      "testing accuracy : 0.9352\n"
     ]
    }
   ],
   "source": [
    "print (\"training accuracy : %.4g\" % metrics.accuracy_score(y_train, pred_train))\n",
    "print (\"testing accuracy : %.4g\" % metrics.accuracy_score(y_test, pred_test))# better than gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=[1 if x=='spam' else 0 for x in y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |   gamma   | learni... | max_depth | min_ch... | n_esti... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9815  \u001b[0m | \u001b[0m 0.7364  \u001b[0m | \u001b[0m 0.2347  \u001b[0m | \u001b[0m 0.1752  \u001b[0m | \u001b[0m 10.25   \u001b[0m | \u001b[0m 2.047   \u001b[0m | \u001b[0m 401.6   \u001b[0m | \u001b[0m 0.6532  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.9674  \u001b[0m | \u001b[0m 0.8648  \u001b[0m | \u001b[0m 0.8208  \u001b[0m | \u001b[0m 0.01113 \u001b[0m | \u001b[0m 18.02   \u001b[0m | \u001b[0m 9.419   \u001b[0m | \u001b[0m 119.5   \u001b[0m | \u001b[0m 0.9397  \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.984   \u001b[0m | \u001b[95m 0.7561  \u001b[0m | \u001b[95m 0.6426  \u001b[0m | \u001b[95m 0.1618  \u001b[0m | \u001b[95m 11.17   \u001b[0m | \u001b[95m 1.329   \u001b[0m | \u001b[95m 401.3   \u001b[0m | \u001b[95m 0.8569  \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.985   \u001b[0m | \u001b[95m 0.8818  \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 0.07639 \u001b[0m | \u001b[95m 17.03   \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 399.3   \u001b[0m | \u001b[95m 1.0     \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.9832  \u001b[0m | \u001b[0m 0.9116  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 17.62   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 407.9   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.9859  \u001b[0m | \u001b[95m 0.5     \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 0.2     \u001b[0m | \u001b[95m 12.26   \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 391.6   \u001b[0m | \u001b[95m 1.0     \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.9836  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1101  \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 2.269   \u001b[0m | \u001b[0m 386.5   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.9828  \u001b[0m | \u001b[0m 0.7114  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 9.222   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 382.5   \u001b[0m | \u001b[0m 0.5348  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.9799  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 14.15   \u001b[0m | \u001b[0m 9.667   \u001b[0m | \u001b[0m 390.5   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.9773  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 3.982   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 390.9   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.981   \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 18.01   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 392.8   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.9826  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 12.35   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 396.5   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from bayes_opt import bayesian_optimization\n",
    "\n",
    "def xgboostcv(max_depth,\n",
    "              learning_rate,\n",
    "              n_estimators,\n",
    "              gamma,\n",
    "              min_child_weight,\n",
    "              subsample,\n",
    "              colsample_bytree,\n",
    "              silent=True,\n",
    "              objective='binary:logistic',\n",
    "              nthread=-1):\n",
    "    return cross_val_score(xgb.XGBClassifier(max_depth=int(max_depth),\n",
    "                                             learning_rate=learning_rate,\n",
    "                                             n_estimators=int(n_estimators),\n",
    "                                             silent=silent,\n",
    "                                             objective=objective,\n",
    "                                             nthread=nthread,\n",
    "                                             gamma=gamma,\n",
    "                                             min_child_weight=min_child_weight,\n",
    "                                             subsample=subsample,\n",
    "                                             colsample_bytree=colsample_bytree),\n",
    "                           x_train,\n",
    "                           Y_train,\n",
    "                           scoring='roc_auc',\n",
    "                           cv=5).mean()\n",
    "\n",
    "    \n",
    "xgboostBO = bayesian_optimization.BayesianOptimization(xgboostcv,\n",
    "                                 {'max_depth': (3, 20),\n",
    "                                  'learning_rate': (0.01, 0.2),\n",
    "                                  'n_estimators': (50, 500),\n",
    "                                  'gamma': (0.01,1.),\n",
    "                                  'min_child_weight': (1, 10),\n",
    "                                  'subsample': (0.5, 1),\n",
    "                                  'colsample_bytree' :(0.5, 1)})\n",
    "xgboostBO.maximize(init_points=2, n_iter = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(colsample_bytree=0.5, gamma=1.0, learning_rate=0.2, max_depth=12,\n",
       "              min_child_weight=1.0, n_estimators=391, seed=1, silent=True,\n",
       "              subsample=1.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB=XGBClassifier(max_depth=12,learning_rate=0.2,n_estimators=391,silent=True,\n",
    "                  objective='binary:logistic',gamma=1.0,min_child_weight=1.0,seed=1,\n",
    "                  subsample=1.0,colsample_bytree=0.5)\n",
    "XGB.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train=XGB.predict(x_train)\n",
    "pred_test=XGB.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy : 0.9974\n",
      "testing accuracy : 0.9487\n"
     ]
    }
   ],
   "source": [
    "print (\"training accuracy : %.4g\" % metrics.accuracy_score(y_train, pred_train))\n",
    "print (\"testing accuracy : %.4g\" % metrics.accuracy_score(y_test, pred_test)) # best of all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import plot_importance\n",
    "plot_importance(XGB)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
