{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice!  You got it all correct.\n",
      "\n",
      " Input 1    Input 2   Linear Combination    Activation Output   Is Correct\n",
      "       0          0                -0.10                    0          Yes\n",
      "       0          1                -0.01                    0          Yes\n",
      "       1          0                -0.01                    0          Yes\n",
      "       1          1                 0.08                    1          Yes\n"
     ]
    }
   ],
   "source": [
    "# build a neural network\n",
    "# AND gate\n",
    "import pandas as pd\n",
    "\n",
    "# TODO: Set weight1, weight2, and bias\n",
    "weight1 = 0.09\n",
    "weight2 = 0.09\n",
    "bias = -0.1\n",
    "\n",
    "# Inputs and outputs\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [False, False, False, True]\n",
    "outputs = []\n",
    "\n",
    "# Generate and check output\n",
    "for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\n",
    "    output = int(linear_combination >= 0)\n",
    "    is_correct_string = 'Yes' if output == correct_output else 'No'\n",
    "    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\n",
    "\n",
    "# Print output\n",
    "num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\n",
    "output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', \n",
    "                                              ' Linear Combination', \n",
    "                                              '  Activation Output',\n",
    "                                              '  Is Correct'])\n",
    "if not num_wrong:\n",
    "    print('Nice!  You got it all correct.\\n')\n",
    "else:\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "print(output_frame.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You got 1 wrong.  Keep trying!\n",
      "\n",
      " Input 1    Input 2    Linear Combination    Activation Output   Is Correct\n",
      "       0          0                  0.10                    1          Yes\n",
      "       0          1                 -0.10                    0           No\n",
      "       1          0                  0.12                    1          Yes\n",
      "       1          1                 -0.08                    0          Yes\n"
     ]
    }
   ],
   "source": [
    "# NOT and gate\n",
    "import pandas as pd\n",
    "\n",
    "# TODO: Set weight1, weight2, and bias\n",
    "weight1 = xx\n",
    "weight2 = xx\n",
    "bias = xx\n",
    "\n",
    "# Inputs and outputs\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [True, True, True, False]\n",
    "outputs = []\n",
    "\n",
    "# Generate and check output\n",
    "for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\n",
    "    output = int(linear_combination >= 0)\n",
    "    is_correct_string = 'Yes' if output == correct_output else 'No'\n",
    "    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\n",
    "\n",
    "# Print output\n",
    "num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\n",
    "output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', \n",
    "                                              '  Linear Combination', \n",
    "                                              '  Activation Output', '  Is Correct'])\n",
    "if not num_wrong:\n",
    "    print('Nice!  You got it all correct.\\n')\n",
    "else:\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "print(output_frame.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "0.4329070950345457\n"
     ]
    }
   ],
   "source": [
    "#Simple network: sigmoid function to make a prediction\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    # TODO: Implement sigmoid function\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "inputs = np.array([0.7, -0.3])\n",
    "weights = np.array([0.1, 0.8])\n",
    "bias = -0.1\n",
    "\n",
    "# TODO: Calculate the output\n",
    "output = sigmoid(np.dot(weights, inputs)+ bias)\n",
    "\n",
    "print('Output:')\n",
    "print(output) # probability of being class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network output:\n",
      "0.7109495026250039\n",
      "Amount of Error:\n",
      "0.022249846328868263\n",
      "Change in Weights:\n",
      "[0.00237973 0.00475946 0.00713919 0.00951892]\n",
      "[ 0.50237973 -0.49524054  0.30713919  0.10951892]\n"
     ]
    }
   ],
   "source": [
    "# gradient descent to change the weight\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    \"\"\"\n",
    "    # Derivative of the sigmoid function\n",
    "    \"\"\"\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "learnrate = 0.5\n",
    "x = np.array([1, 2, 3, 4])\n",
    "y = np.array(0.5)\n",
    "\n",
    "# Initial weights and bias\n",
    "w = np.array([0.5, -0.5, 0.3, 0.1])\n",
    "b = 0.1\n",
    "\n",
    "### Calculate one gradient descent step for each weight\n",
    "### Note: Some steps have been consilated, so there are\n",
    "###       fewer variable names than in the above sample code\n",
    "\n",
    "# TODO: Calculate the node's linear combination of inputs and weights\n",
    "h = np.dot(x, w)\n",
    "\n",
    "# TODO: Calculate output of neural network\n",
    "nn_output = sigmoid(h+b)\n",
    "\n",
    "# TODO: Calculate error of neural network\n",
    "error =0.5*((nn_output-y)**2)\n",
    "\n",
    "# TODO: Calculate the error term\n",
    "#       Remember, this requires the output gradient, which we haven't\n",
    "#       specifically added a variable for.\n",
    "error_term = error*sigmoid_prime(h)\n",
    "\n",
    "# TODO: Calculate change in weights\n",
    "del_w = learnrate*error_term*x\n",
    "\n",
    "print('Neural Network output:')\n",
    "print(nn_output)\n",
    "print('Amount of Error:')\n",
    "print(error)\n",
    "print('Change in Weights:')\n",
    "print(del_w)\n",
    "print(w+del_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn neural network\n",
    "# It has various chemical features of different wines, all grown in the same region in Italy,\n",
    "# but the data is labeled by three different possible cultivars. \n",
    "# We will try to build a model that can classify what cultivar a wine belongs to based on its \n",
    "#chemical features using Neural Networks\n",
    "import pandas as pd\n",
    "wine = pd.read_csv('wine.data', names = [\"Cultivator\", \"Alchol\", \"Malic_Acid\", \"Ash\", \n",
    "                                         \"Alcalinity_of_Ash\", \"Magnesium\", \"Total_phenols\", \n",
    "                                         \"Falvanoids\", \"Nonflavanoid_phenols\", \"Proanthocyanins\",\n",
    "                                         \"Color_intensity\", \"Hue\", \"OD280\", \"Proline\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cultivator                int64\n",
       "Alchol                  float64\n",
       "Malic_Acid              float64\n",
       "Ash                     float64\n",
       "Alcalinity_of_Ash       float64\n",
       "Magnesium                 int64\n",
       "Total_phenols           float64\n",
       "Falvanoids              float64\n",
       "Nonflavanoid_phenols    float64\n",
       "Proanthocyanins         float64\n",
       "Color_intensity         float64\n",
       "Hue                     float64\n",
       "OD280                   float64\n",
       "Proline                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cultivator</th>\n",
       "      <th>Alchol</th>\n",
       "      <th>Malic_Acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity_of_Ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_phenols</th>\n",
       "      <th>Falvanoids</th>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cultivator  Alchol  Malic_Acid   Ash  Alcalinity_of_Ash  Magnesium  \\\n",
       "0           1   14.23        1.71  2.43               15.6        127   \n",
       "1           1   13.20        1.78  2.14               11.2        100   \n",
       "2           1   13.16        2.36  2.67               18.6        101   \n",
       "3           1   14.37        1.95  2.50               16.8        113   \n",
       "4           1   13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total_phenols  Falvanoids  Nonflavanoid_phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color_intensity   Hue  OD280  Proline  \n",
       "0             5.64  1.04   3.92     1065  \n",
       "1             4.38  1.05   3.40     1050  \n",
       "2             5.68  1.03   3.17     1185  \n",
       "3             7.80  0.86   3.45     1480  \n",
       "4             4.32  1.04   2.93      735  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cultivator</th>\n",
       "      <td>178.0</td>\n",
       "      <td>1.938202</td>\n",
       "      <td>0.775035</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alchol</th>\n",
       "      <td>178.0</td>\n",
       "      <td>13.000618</td>\n",
       "      <td>0.811827</td>\n",
       "      <td>11.03</td>\n",
       "      <td>12.3625</td>\n",
       "      <td>13.050</td>\n",
       "      <td>13.6775</td>\n",
       "      <td>14.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malic_Acid</th>\n",
       "      <td>178.0</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.6025</td>\n",
       "      <td>1.865</td>\n",
       "      <td>3.0825</td>\n",
       "      <td>5.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ash</th>\n",
       "      <td>178.0</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>1.36</td>\n",
       "      <td>2.2100</td>\n",
       "      <td>2.360</td>\n",
       "      <td>2.5575</td>\n",
       "      <td>3.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcalinity_of_Ash</th>\n",
       "      <td>178.0</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>10.60</td>\n",
       "      <td>17.2000</td>\n",
       "      <td>19.500</td>\n",
       "      <td>21.5000</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Magnesium</th>\n",
       "      <td>178.0</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>70.00</td>\n",
       "      <td>88.0000</td>\n",
       "      <td>98.000</td>\n",
       "      <td>107.0000</td>\n",
       "      <td>162.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_phenols</th>\n",
       "      <td>178.0</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.7425</td>\n",
       "      <td>2.355</td>\n",
       "      <td>2.8000</td>\n",
       "      <td>3.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Falvanoids</th>\n",
       "      <td>178.0</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.2050</td>\n",
       "      <td>2.135</td>\n",
       "      <td>2.8750</td>\n",
       "      <td>5.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <td>178.0</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <td>178.0</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.2500</td>\n",
       "      <td>1.555</td>\n",
       "      <td>1.9500</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Color_intensity</th>\n",
       "      <td>178.0</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>1.28</td>\n",
       "      <td>3.2200</td>\n",
       "      <td>4.690</td>\n",
       "      <td>6.2000</td>\n",
       "      <td>13.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hue</th>\n",
       "      <td>178.0</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.7825</td>\n",
       "      <td>0.965</td>\n",
       "      <td>1.1200</td>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OD280</th>\n",
       "      <td>178.0</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.9375</td>\n",
       "      <td>2.780</td>\n",
       "      <td>3.1700</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proline</th>\n",
       "      <td>178.0</td>\n",
       "      <td>746.893258</td>\n",
       "      <td>314.907474</td>\n",
       "      <td>278.00</td>\n",
       "      <td>500.5000</td>\n",
       "      <td>673.500</td>\n",
       "      <td>985.0000</td>\n",
       "      <td>1680.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count        mean         std     min       25%  \\\n",
       "Cultivator            178.0    1.938202    0.775035    1.00    1.0000   \n",
       "Alchol                178.0   13.000618    0.811827   11.03   12.3625   \n",
       "Malic_Acid            178.0    2.336348    1.117146    0.74    1.6025   \n",
       "Ash                   178.0    2.366517    0.274344    1.36    2.2100   \n",
       "Alcalinity_of_Ash     178.0   19.494944    3.339564   10.60   17.2000   \n",
       "Magnesium             178.0   99.741573   14.282484   70.00   88.0000   \n",
       "Total_phenols         178.0    2.295112    0.625851    0.98    1.7425   \n",
       "Falvanoids            178.0    2.029270    0.998859    0.34    1.2050   \n",
       "Nonflavanoid_phenols  178.0    0.361854    0.124453    0.13    0.2700   \n",
       "Proanthocyanins       178.0    1.590899    0.572359    0.41    1.2500   \n",
       "Color_intensity       178.0    5.058090    2.318286    1.28    3.2200   \n",
       "Hue                   178.0    0.957449    0.228572    0.48    0.7825   \n",
       "OD280                 178.0    2.611685    0.709990    1.27    1.9375   \n",
       "Proline               178.0  746.893258  314.907474  278.00  500.5000   \n",
       "\n",
       "                          50%       75%      max  \n",
       "Cultivator              2.000    3.0000     3.00  \n",
       "Alchol                 13.050   13.6775    14.83  \n",
       "Malic_Acid              1.865    3.0825     5.80  \n",
       "Ash                     2.360    2.5575     3.23  \n",
       "Alcalinity_of_Ash      19.500   21.5000    30.00  \n",
       "Magnesium              98.000  107.0000   162.00  \n",
       "Total_phenols           2.355    2.8000     3.88  \n",
       "Falvanoids              2.135    2.8750     5.08  \n",
       "Nonflavanoid_phenols    0.340    0.4375     0.66  \n",
       "Proanthocyanins         1.555    1.9500     3.58  \n",
       "Color_intensity         4.690    6.2000    13.00  \n",
       "Hue                     0.965    1.1200     1.71  \n",
       "OD280                   2.780    3.1700     4.00  \n",
       "Proline               673.500  985.0000  1680.00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cultivator              False\n",
       "Alchol                  False\n",
       "Malic_Acid              False\n",
       "Ash                     False\n",
       "Alcalinity_of_Ash       False\n",
       "Magnesium               False\n",
       "Total_phenols           False\n",
       "Falvanoids              False\n",
       "Nonflavanoid_phenols    False\n",
       "Proanthocyanins         False\n",
       "Color_intensity         False\n",
       "Hue                     False\n",
       "OD280                   False\n",
       "Proline                 False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.isnull().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wine.drop('Cultivator',axis=1)\n",
    "y = wine['Cultivator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y) # multiple-class classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    71\n",
       "1    59\n",
       "3    48\n",
       "Name: Cultivator, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine['Cultivator'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The neural network in Python may have difficulty converging before the maximum number \n",
    "#of iterations allowed if the data is not normalized. Multi-layer Perceptron is sensitive \n",
    "#to feature scaling, so it is highly recommended to scale your data. Note that you must \n",
    "#apply the same scaling to the test set for meaningful results. There are a lot of different \n",
    "#methods for normalization of data, we will use the built-in StandardScaler for standardization.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit only to the training data\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now apply the transformations to the data:\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(13, 13, 13), max_iter=500)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "from sklearn.neural_network import MLPClassifier # MLPRegressor\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(13,13,13),max_iter=500)\n",
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction and evaluation\n",
    "predictions = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics as sm\n",
    "sm.accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14  0  0]\n",
      " [ 0 14  0]\n",
      " [ 0  0  8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coefs_ is a list of weight matrices, where weight matrix at index i \n",
    "# represents the weights between layer i and layer i+1.\n",
    "\n",
    "# intercepts_ is a list of bias vectors, where the vector at index i \n",
    "# represents the bias values added to layer i+1.\n",
    "len(mlp.coefs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.56045805,  0.50389197, -0.04182295,  0.37288405, -0.58489304,\n",
       "          0.30016227,  0.36061449, -0.3385583 , -0.47613741, -0.47483644,\n",
       "         -0.07992364,  0.21746255, -0.12913229],\n",
       "        [-0.35578154,  0.26974452, -0.36021539, -0.08689012, -0.32748639,\n",
       "         -0.19770268,  0.35864261, -0.33949587, -0.02434666, -0.12649439,\n",
       "         -0.56964589,  0.03499124, -0.14843846],\n",
       "        [-0.41032303,  0.53415099,  0.44189009,  0.41278194, -0.26211609,\n",
       "         -0.47912295,  0.33592402, -0.16149653, -0.3753309 , -0.07810315,\n",
       "         -0.37706574,  0.27152471, -0.06874705],\n",
       "        [ 0.17504705, -0.14151656,  0.09386767, -0.1864749 , -0.224643  ,\n",
       "          0.66861659,  0.44437804,  0.50620694,  0.63521708,  0.01833292,\n",
       "          0.25347363, -0.5718091 , -0.08551059],\n",
       "        [-0.38851435, -0.01759612, -0.16606882, -0.12618261,  0.39363223,\n",
       "         -0.27488981, -0.28357646, -0.05459729, -0.4079397 ,  0.47783   ,\n",
       "         -0.29913007,  0.40362315,  0.19015561],\n",
       "        [-0.48828207, -0.50242485,  0.35976568,  0.29548671,  0.12546299,\n",
       "          0.06814954, -0.529592  , -0.2504406 , -0.51590633,  0.30773907,\n",
       "          0.2868601 ,  0.01392159, -0.60148856],\n",
       "        [-0.22650742, -0.25442019,  0.38118638,  0.24607049,  0.29952049,\n",
       "         -0.20222363, -0.51153623,  0.14368755,  0.19043078,  0.06315887,\n",
       "          0.47024031,  0.17365792, -0.23019303],\n",
       "        [-0.01247606, -0.37907798, -0.55308843, -0.50875522,  0.19209608,\n",
       "         -0.06668522,  0.15681683,  0.40278282, -0.14747828, -0.00088103,\n",
       "          0.12377431, -0.36536947, -0.21244913],\n",
       "        [-0.45030772, -0.37594761,  0.47329959,  0.29896462,  0.03036879,\n",
       "          0.39864741,  0.1834046 , -0.38344957,  0.42795423,  0.06759046,\n",
       "          0.23838518,  0.42563492, -0.34346458],\n",
       "        [-0.54782493, -0.10176692, -0.24361759,  0.4002896 ,  0.19954362,\n",
       "         -0.65907545,  0.1247992 , -0.10560948, -0.46922414, -0.54632429,\n",
       "         -0.09795787,  0.25422929,  0.06427754],\n",
       "        [ 0.21643309,  0.04252269,  0.06406084,  0.36655139,  0.6112473 ,\n",
       "         -0.06239745, -0.14461143, -0.18765074,  0.01623283, -0.21706961,\n",
       "          0.15165344,  0.15840185, -0.64725692],\n",
       "        [-0.20277877,  0.27552104, -0.07121848, -0.23944975, -0.14115967,\n",
       "          0.25487148, -0.39068704,  0.16540809,  0.23984317, -0.15800791,\n",
       "          0.33354543,  0.06098731, -0.08694664],\n",
       "        [-0.01675701,  0.08348151, -0.51104009,  0.51991131, -0.28455599,\n",
       "         -0.46093641, -0.61412775, -0.03967986, -0.03777849, -0.54325357,\n",
       "          0.1707604 , -0.06974803, -0.03555471]]),\n",
       " array([[ 0.15488397, -0.30064531, -0.30710328,  0.38631787,  0.31402303,\n",
       "          0.08807658, -0.17470376, -0.01038133,  0.35945602,  0.33354333,\n",
       "          0.4875119 ,  0.40531108,  0.33313819],\n",
       "        [-0.43080032, -0.14412319,  0.40497462,  0.17068329, -0.52790948,\n",
       "         -0.23524215,  0.33266111, -0.49781827, -0.06403933,  0.20357427,\n",
       "          0.2936396 ,  0.24478461, -0.11635271],\n",
       "        [ 0.32068686, -0.02638162, -0.18633234,  0.32797459,  0.16792434,\n",
       "          0.3072114 ,  0.24816156,  0.25580264, -0.15667247,  0.03202734,\n",
       "         -0.1003313 , -0.03252675,  0.60775976],\n",
       "        [-0.22669238,  0.59386996,  0.08613626,  0.43070797, -0.06323117,\n",
       "          0.16318127,  0.15315445, -0.31132075,  0.46502045,  0.04346038,\n",
       "         -0.51032877,  0.14731452, -0.23083793],\n",
       "        [ 0.57378399,  0.2136376 ,  0.21011366, -0.10720629, -0.5271382 ,\n",
       "          0.27200783, -0.13857359,  0.5591514 ,  0.6558091 ,  0.38208814,\n",
       "         -0.05765144, -0.30679189,  0.48678251],\n",
       "        [-0.04313578, -0.462439  ,  0.02265939,  0.41302373,  0.15454048,\n",
       "         -0.087319  , -0.37933123,  0.24823876,  0.63737222, -0.37811668,\n",
       "          0.11535609,  0.22098988,  0.38672615],\n",
       "        [ 0.03950567,  0.34652364,  0.11786749, -0.26630033,  0.2553576 ,\n",
       "          0.45308832,  0.24512505,  0.42975398, -0.20706787, -0.13513481,\n",
       "          0.42400865,  0.35166861,  0.44955819],\n",
       "        [ 0.39929611,  0.42499122, -0.05998221, -0.12469112, -0.45231998,\n",
       "          0.1290374 , -0.4603316 ,  0.11055423,  0.19141308, -0.24733268,\n",
       "          0.21390349, -0.19944817, -0.23400493],\n",
       "        [ 0.43339896, -0.3514723 , -0.37468792,  0.02228491,  0.20061953,\n",
       "         -0.44782394,  0.07509462, -0.27942761, -0.24096291,  0.02970993,\n",
       "          0.12639799, -0.05136463,  0.37868184],\n",
       "        [ 0.58657734, -0.10348676, -0.00113407,  0.27852228, -0.28757498,\n",
       "         -0.24561791, -0.59336146, -0.28690143,  0.62456535,  0.25583585,\n",
       "          0.33240396,  0.04116444, -0.14751845],\n",
       "        [-0.24853324, -0.22368855, -0.00990415,  0.24352557,  0.08839743,\n",
       "         -0.23970115,  0.50272462,  0.30838141,  0.24422082,  0.18799117,\n",
       "         -0.00938732, -0.31278559, -0.02366184],\n",
       "        [ 0.13485581, -0.22937057, -0.4127962 , -0.23785617, -0.56852707,\n",
       "          0.48364476,  0.37984954, -0.08465041, -0.08225195,  0.25499305,\n",
       "         -0.06506535, -0.23083613, -0.06603222],\n",
       "        [-0.18621505,  0.29130168,  0.28549819, -0.42736779, -0.1793108 ,\n",
       "          0.2831705 , -0.07216765,  0.52261924, -0.03388685, -0.39103515,\n",
       "         -0.23400025,  0.3593956 , -0.26749816]]),\n",
       " array([[-0.35285453, -0.52948576, -0.39454972,  0.27289471, -0.25811898,\n",
       "         -0.0560094 ,  0.49636089, -0.42313467,  0.43126816, -0.34203052,\n",
       "         -0.53818859,  0.15497255,  0.22800901],\n",
       "        [ 0.54395951,  0.38356405,  0.50551233, -0.3477347 , -0.34786869,\n",
       "          0.09815547,  0.16069777,  0.62196543, -0.06777903, -0.03053475,\n",
       "          0.4268672 ,  0.10150361,  0.32337606],\n",
       "        [ 0.53450696, -0.01534758,  0.36326825,  0.10683354, -0.54451597,\n",
       "          0.25070951, -0.2285617 ,  0.44920659, -0.29408972,  0.39423266,\n",
       "          0.10178928, -0.39675575,  0.3189605 ],\n",
       "        [-0.54897586,  0.0505387 ,  0.57444807,  0.5783189 ,  0.14438207,\n",
       "          0.19712971,  0.04451954, -0.42744345, -0.0761267 ,  0.09533726,\n",
       "          0.15289117,  0.3455059 ,  0.27525094],\n",
       "        [-0.36859556, -0.05205689, -0.48589124,  0.20527503,  0.01535959,\n",
       "          0.43064406, -0.06141342, -0.37378238, -0.27521891,  0.18095917,\n",
       "          0.04069554, -0.4224492 , -0.32654209],\n",
       "        [ 0.36348556, -0.32193281,  0.5315449 ,  0.07685792, -0.42353762,\n",
       "         -0.55682921,  0.35263055,  0.05651513, -0.17784311,  0.3126261 ,\n",
       "          0.57503563,  0.70008386,  0.07524013],\n",
       "        [-0.04049841, -0.14479764,  0.53325776,  0.0143892 , -0.25438309,\n",
       "          0.27861005, -0.48693436, -0.03661303, -0.54863826, -0.18723621,\n",
       "         -0.35206107, -0.09423408, -0.59861594],\n",
       "        [ 0.3152212 ,  0.13104353,  0.19190569,  0.34158502,  0.03209671,\n",
       "         -0.1417583 ,  0.28789871, -0.07384684,  0.57861552, -0.25673054,\n",
       "          0.60271384, -0.57466237,  0.54827461],\n",
       "        [-0.18939145,  0.64697983, -0.2066464 ,  0.29044701,  0.59739075,\n",
       "          0.1282381 ,  0.29552184, -0.01041396,  0.12104209,  0.00311213,\n",
       "         -0.07837565,  0.50917642, -0.40174847],\n",
       "        [-0.23148776,  0.55754884,  0.57432466,  0.04430043,  0.15679615,\n",
       "         -0.19268593, -0.16517875, -0.11132578, -0.06135767, -0.00881163,\n",
       "         -0.56549088,  0.59784675,  0.36782686],\n",
       "        [ 0.31076054, -0.04574939, -0.14207409,  0.25916283,  0.31294827,\n",
       "         -0.24203216,  0.54713537,  0.47430368,  0.54114889,  0.32907052,\n",
       "          0.18237786, -0.15353599,  0.54203875],\n",
       "        [ 0.57326524, -0.72721586, -0.23246582, -0.3041412 ,  0.39397664,\n",
       "          0.49491261, -0.3446035 ,  0.29532406, -0.02859747,  0.62218913,\n",
       "          0.45007835,  0.08918737,  0.20009353],\n",
       "        [-0.29041169, -0.35509934, -0.66524848,  0.59546248,  0.50793986,\n",
       "          0.64105886,  0.68453086, -0.22207078,  0.46174323,  0.26237451,\n",
       "          0.14298973, -0.39514842,  0.15140352]]),\n",
       " array([[-0.10941006, -0.13882316,  0.67991164],\n",
       "        [ 0.03321214, -0.52681355, -0.77435383],\n",
       "        [ 0.56380211, -0.07882038,  0.15303571],\n",
       "        [-0.43834292, -0.30684401, -0.74767845],\n",
       "        [-0.26020015,  0.24704529, -0.3027025 ],\n",
       "        [ 0.09211481,  0.4527247 , -0.31834697],\n",
       "        [-0.12754137,  0.51127175, -0.07421796],\n",
       "        [-0.06378778,  0.20344543,  0.80303801],\n",
       "        [-0.55033706,  0.69454928, -0.00307912],\n",
       "        [-0.3954256 , -0.00127768,  0.57379254],\n",
       "        [-0.19738585, -0.36749551,  0.35028598],\n",
       "        [-0.1387426 , -0.52451837, -0.67954616],\n",
       "        [-0.55152153, -0.35496473, -0.33879016]])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.coefs_ # weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.14728411,  0.16278049,  0.07368504,  0.56776107, -0.14044289,\n",
       "         0.04522384, -0.19198004,  0.47860733,  0.49665467, -0.1309748 ,\n",
       "         0.20005109,  0.26373657,  0.1311257 ]),\n",
       " array([ 0.06919803,  0.58571053,  0.09603644, -0.04776055,  0.0562785 ,\n",
       "         0.08000764,  0.2338793 ,  0.56881094,  0.1127304 ,  0.54555994,\n",
       "         0.50680375, -0.12428209, -0.25909107]),\n",
       " array([-0.24098676,  0.59238292,  0.30207452, -0.3074918 ,  0.21958009,\n",
       "         0.1296817 , -0.05501124, -0.31390591,  0.24122083, -0.05446165,\n",
       "         0.24943495,  0.16913738,  0.20150917]),\n",
       " array([ 0.30540561, -0.48188326, -0.39348885])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.intercepts_ #bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
